{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3 0.7 1.1]]\n",
      "[[0.57444252 0.66818777 0.75026011]]\n",
      "(1, 3)\n",
      "(3, 2)\n",
      "(2,)\n",
      "[[0.51615984 1.21402696]]\n",
      "[[0.62624937 0.7710107 ]]\n",
      "[[0.31682708 0.69627909]]\n",
      "[[0.31682708 0.69627909]]\n"
     ]
    }
   ],
   "source": [
    "# 3層ニューラルネットワークの実装\n",
    "# ニューロン 3→3→2→2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 活性化関数の定義(非線形変換)\n",
    "# シグモイド関数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# 恒等関数(今回は実装なし.代表的な関数:分類問題→softmax関数 など)\n",
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "# -------- ↓ニューラルネット↓ -------- #\n",
    "\n",
    "# 入力値 x1,x2\n",
    "X = np.array([[1.0, 0.5]]) \n",
    "\n",
    "# --------- ↓入力層から第1層への信号の伝播↓ --------- #\n",
    "\n",
    "# 重み w  \n",
    "# array[0]は入力層 x1 から第1層(a1,a2,a3)にかかる重み. \n",
    "# array[1]は入力層 x2 から第1層(a1,a2,a3)にかかる重み.\n",
    "W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]]) \n",
    "\n",
    "# バイアス B\n",
    "# 第1層(a1,a2,a3)に加える固定値(ニューロンの発火しやすさの調節)\n",
    "B1 = np.array([0.1, 0.2, 0.3]) \n",
    "\n",
    "# 第1層 A1 (a1,a2,a3) の「重み付き和」(重み付き信号とバイアスの総和)\n",
    "A1 = np.dot(X, W1) + B1\n",
    "\n",
    "# 活性化関数(sigmoid)による非線形変換\n",
    "Z1 = sigmoid(A1)\n",
    "\n",
    "print(A1)\n",
    "print(Z1)\n",
    "\n",
    "# --------- ↑入力層から第1層への信号の伝播↑ --------- #\n",
    "\n",
    "# --------- ↓第1層から第2層への信号の伝播↓ --------- #\n",
    "\n",
    "# 重み\n",
    "W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "# バイアス\n",
    "B2 = np.array([0.1, 0.2])\n",
    "\n",
    "print(Z1.shape)\n",
    "print(W2.shape)\n",
    "print(B2.shape)\n",
    "\n",
    "# 第2層 A2 の「重み付き和」(重み付き信号とバイアスの総和)\n",
    "A2 = np.dot(Z1, W2) + B2\n",
    "\n",
    "# 活性化関数(sigmoid)による非線形変換\n",
    "Z2 = sigmoid(A2)\n",
    "\n",
    "print(A2)\n",
    "print(Z2)\n",
    "\n",
    "# --------- ↑第1層から第2層への信号の伝播↑ --------- #\n",
    "\n",
    "# --------- ↓第2層から出力層への信号の伝播↓ --------- #\n",
    "\n",
    "# 重み\n",
    "W3 = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "# バイアス\n",
    "B3 = np.array([0.1, 0.2])\n",
    "\n",
    "# 出力層「重み付き和」(重み付き信号とバイアスの総和)\n",
    "A3 = np.dot(Z2, W3) + B3\n",
    "\n",
    "# 恒等関数\n",
    "Y = identity_function(A3)\n",
    "\n",
    "print(A3)\n",
    "print(Y)\n",
    "\n",
    "# --------- ↑第2層から出力層への信号の伝播↑ --------- #\n",
    "\n",
    "# -------- ↑ニューラルネット↑ -------- #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "# 上記実装のまとめ\n",
    "import numpy as np\n",
    "\n",
    "# パラメータの初期化\n",
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]]) \n",
    "    network['b1'] = np.array([0.1, 0.2, 0.3]) \n",
    "    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "    network['b2'] = np.array([0.1, 0.2])\n",
    "    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "    network['b3'] = np.array([0.1, 0.2])\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "# 活性化,恒等関数の定義\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "# 入力→出力の伝播処理 = forward\n",
    "def forward(network, x):\n",
    "    w1, w2, w3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, w1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, w2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, w3) + b3\n",
    "    y = identity_function(a3)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "network = init_network()\n",
    "x = np.array([1.0, 0.5])\n",
    "y = forward(network, x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力層の設計\n",
    "# 出力層は一般的に回帰問題：恒等関数,分類問題：ソフトマックス関数を用いる\n",
    "\n",
    "# 恒等関数は入力された値をそのまま返す\n",
    "def identity_function(a):\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ソフトマックス関数 インタプリタ\n",
    "a = np.array([0.3, 2.9, 4.0])\n",
    "exp_a = np.exp(a) # 指数関数\n",
    "print(exp_a)\n",
    "\n",
    "sum_exp_a = np.sum(exp_a)\n",
    "print(sum_exp_a)\n",
    "\n",
    "y = exp_a / sum_exp_a\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ソフトマックス関数_オーバーフロー対策なし\n",
    "def softmax_tmp(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 -10 -20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mntt0\\AppData\\Local\\Temp\\ipykernel_2860\\930269338.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(a) / np.sum(np.exp(a)) # ソフトマックス関数の計算\n",
      "C:\\Users\\mntt0\\AppData\\Local\\Temp\\ipykernel_2860\\930269338.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "  np.exp(a) / np.sum(np.exp(a)) # ソフトマックス関数の計算\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ソフトマックス関数のオーバーフロー対策\n",
    "# 指数計算のため値が容易に巨大になりえる.\n",
    "# 分母分子に任意の定数logCを足し引きしても結果は変わらないため利用する.\n",
    "# logC の値は任意だがオーバーフロー対策の一つとして入力信号の中で最大の値を用いることが一般的\n",
    "\n",
    "# オーバーフロー対策をせずに計算\n",
    "a = np.array([1010,1000,990])\n",
    "np.exp(a) / np.sum(np.exp(a)) # ソフトマックス関数の計算\n",
    "\n",
    "# ↓出力結果_オーバーフローしている.\n",
    "# C:\\Users\\mntt0\\AppData\\Local\\Temp\\ipykernel_2860\\2240196628.py:8: RuntimeWarning: overflow encountered in exp\n",
    "#   np.exp(a) / np.sum(np.exp(a)) # ソフトマックス関数の計算\n",
    "# C:\\Users\\mntt0\\AppData\\Local\\Temp\\ipykernel_2860\\2240196628.py:8: RuntimeWarning: invalid value encountered in divide\n",
    "#   np.exp(a) / np.sum(np.exp(a)) # ソフトマックス関数の計算\n",
    "# array([nan, nan, nan])\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# オーバーフロー対策をして計算\n",
    "a = np.array([1010,1000,990])\n",
    "c = np.max(a)\n",
    "print(a-c) # [  0 -10 -20]\n",
    "\n",
    "np.exp(a-c) / np.sum(np.exp(a-c)) # ソフトマックス関数の計算\n",
    "\n",
    "# ↓出力結果_オーバーフローせず計算可能\n",
    "# array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ソフトマックス関数\n",
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a-c) # オーバーフロー対策\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "# ソフトマックス関数試し使い\n",
    "a = np.array([0.3, 2.9, 4.0])\n",
    "y = softmax(a)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**【コラム】**<br>\n",
    "\n",
    "ソフトマックス関数を通しても値の大小の順番は変わらない。<br>\n",
    "入力値が[a > b > c] の場合、ソフトマックス関数を通した後も[a > b > c]となる。<br>\n",
    "ソフトマックス関数を通すことで総和を1に収め確率として扱うことができるが、入力値の大小から特定は可能なため、<br>\n",
    "コンピューターの計算リソースを削減するために「学習」「推論」の「推論」の出力層には用いないことが一般的。<br>\n",
    "出力層にソフトマックス関数を用いる理由は「学習」のフェーズに関係してくる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
